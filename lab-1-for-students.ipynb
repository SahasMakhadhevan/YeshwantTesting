{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat_minor": 5,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": "# Lab 1 - POD analysis of separated flow past a NACA0018 airfoil ",
      "metadata": {},
      "id": "fd871a38"
    },
    {
      "cell_type": "markdown",
      "source": "In this lab we are going to apply POD to obtain a better understanding of the structure and evolution of the flow past a NACA0018 airfoil. In addition, this lab will teach you practical data manipulation skills using NumPy.\n\nData for this lab has been collected by Dr Sean Symon for his PhD (see [this link](https://www.cambridge.org/core/journals/journal-of-fluid-mechanics/article/tale-of-two-airfoils-resolventbased-modelling-of-an-oscillator-versus-an-amplifier-from-an-experimental-mean/2CE698E25A77016C41636048BCFA17AE)). The data has been collected from Particle Image Velocimetry (PIV), a optical measurement technique (i.e. using a camera) that measures the dislacement of small smoke particles released into the flow to extract two velocity components in a plane illuminated by a LASER sheet. You can find more about PIV on its Wikipedia [article](https://en.wikipedia.org/wiki/Particle_image_velocimetry), or by taking the Experimental Methods for Aerodynamics module SESA6070. Details of the experiments can be found in the journal article referenced above (or by talking to Dr Symon).\n\nTwo datasets are available, at two angles of attack: $\\alpha = 0$ and 10 degrees. We'll start by examining the second case, where large-scale flow separation is expected on the upper surface of the airfoil. You are welcome to examine the other case in your own time.\n\nWe will start with a few basic imports:",
      "metadata": {},
      "id": "da66e207"
    },
    {
      "cell_type": "code",
      "source": "import matplotlib.pyplot as plt\nimport scipy.io\nimport numpy as np\n\n%matplotlib qt",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "0c1f55be"
    },
    {
      "cell_type": "markdown",
      "source": "and also import a function from a custom module that we will use to plot the airfoil.",
      "metadata": {},
      "id": "e44599d4"
    },
    {
      "cell_type": "code",
      "source": "from airfoil import plot_airfoil",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "862967b4"
    },
    {
      "cell_type": "markdown",
      "source": "Now, let's start by loading the data. These are Matlab files, which we can also open using `scipy.io.loadmat`. Make sure to replace the path to suit your own file system.",
      "metadata": {},
      "id": "bd6a2bce"
    },
    {
      "cell_type": "code",
      "source": "# use this variable later too\nAoA = 10\n\n# load file\nmat = scipy.io.loadmat(\"airfoil-PIV-data/AoA=%d.mat\" % AoA)",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "4bfc70c0"
    },
    {
      "cell_type": "markdown",
      "source": "The variable `mat` is simply a normal Python dictionary that contains a bunch of things. ",
      "metadata": {},
      "id": "77265fd3"
    },
    {
      "cell_type": "code",
      "source": "mat;",
      "metadata": {
        "tags": []
      },
      "execution_count": null,
      "outputs": [],
      "id": "c537da23"
    },
    {
      "cell_type": "markdown",
      "source": "Most of the values in the dictionary are NumPy arrays with data. The most important variables are the grid points `mat[\"x\"]` and `mat[\"y\"]` and the velocity data `mat[\"u\"]` and `mat[\"v\"]`, for the two velocity components.\n\nThe grid points are stored in 2D arrays:",
      "metadata": {},
      "id": "1c555ad5"
    },
    {
      "cell_type": "code",
      "source": "mat[\"x\"].shape, mat[\"y\"].shape",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "4a0075ef"
    },
    {
      "cell_type": "markdown",
      "source": "and we have `nx=176` points along the `x` axis (the streamwise direction) and `ny=46` points along the `y` axis (the transverse direction).\n\nFor the velocity components, we have 3D arrays:",
      "metadata": {},
      "id": "f3fa4ead"
    },
    {
      "cell_type": "code",
      "source": "mat[\"u\"].shape, mat[\"v\"].shape",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "5203e8b5"
    },
    {
      "cell_type": "markdown",
      "source": "where the first index is associated with time. More specifically, we have 3400 snapshots so `mat[\"u\"][0, :, :]` will be the `u` velocity field at time `t=0`, `mat[\"u\"][1, :, :]` will be the `u` velocity field at time `t=dt` and so on.\n\nThe data is time resolved and the time interval is:",
      "metadata": {},
      "id": "f34576fe"
    },
    {
      "cell_type": "code",
      "source": "mat[\"dt\"]",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "339aed76"
    },
    {
      "cell_type": "markdown",
      "source": "This is a small quantity, and shows that we need roughly 1/0.008 = 125 snapshots for a fluid particle to travel across the entire chord of the airfoil, at the external flow speed.\n\nNote that all these kinematic quantities have been normalised using the chord $c$ and the external velocity $u_\\infty$. \n\nLet's store some of these variables for later use.",
      "metadata": {},
      "id": "3bc48eb7"
    },
    {
      "cell_type": "code",
      "source": "m, nx, ny = mat[\"u\"].shape",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "308c3c58"
    },
    {
      "cell_type": "markdown",
      "source": "### Task 1 - Visualising the data",
      "metadata": {},
      "id": "39d6e99a"
    },
    {
      "cell_type": "markdown",
      "source": "We'll start by plotting one snapshot, so you can learn how to visualise this dataset. We'll plot the $u$ velocity component, using the `contourf` function and also plot vectors to visualise the velocity field using `quiver`. Here is how to do it.",
      "metadata": {},
      "id": "4dc9ae92"
    },
    {
      "cell_type": "code",
      "source": "plt.figure(0)\nplt.clf()\n\n# plot contours from -1.5 to 1.5\nlevels = np.linspace(-1.5, 1.5, 20)\nplt.contourf(mat[\"x\"], mat[\"y\"], mat[\"u\"][10], levels, cmap=\"seismic\")\n\n# add colorbar\nplt.colorbar(shrink=0.25, ticks=[-1.5, 0, 1.5], label=\"$\\overline{u}/u_\\infty$\")\n\n# only plot one vector every three, to avoid crowding\nskip = 3\nplt.quiver(mat[\"x\"][::skip, ::skip], \n           mat[\"y\"][::skip, ::skip], \n           mat[\"u\"][0][::skip, ::skip], \n           mat[\"v\"][0][::skip, ::skip])\n\n# must set the aspect ratio to 1 for the x and y axis to have the same metric\nplt.gca().set_aspect(1)\n\n# always add labels\nplt.xlabel(\"x/c\")\nplt.ylabel(\"y/c\")\n\n# also plot the airfoil\nplot_airfoil(AoA)",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "368abe14"
    },
    {
      "cell_type": "markdown",
      "source": "Note all the elements of the plot (colorbar, labels, etc) and make sure you use a similar style for your coursework. Note also the white area near the airfoil: this is where we do not have data and the array simply contain a bunch of zeros in this area. This is standard in experiments!",
      "metadata": {},
      "id": "bec4a36f"
    },
    {
      "cell_type": "markdown",
      "source": "Since the data is time resolved, we can create a little movie to get a first grasp of this flow. Note that I am using `plt.pause` (this has been tested on a mac computer, but it should work on windows too). I am plotting one every 20 snapshots of the first 1000 snapshots, to ensure the video proceeds at a decent speed. I am plotting contours of the $u$ and $v$ velocities.",
      "metadata": {},
      "id": "a33d83d6"
    },
    {
      "cell_type": "code",
      "source": "plt.figure(1, figsize=(7, 5))\nplt.subplots_adjust(top=0.96, hspace=0.1, bottom=0.05, right=0.99)\nplt.clf()\n\nlevels = np.linspace(-1.5, 1.5, 30)\n\nfor it in range(0, 1000, 20):\n    # need to clear the figure before every loop iteration\n    plt.clf()\n\n    plt.subplot(211)\n    plt.contourf(mat[\"x\"], mat[\"y\"], mat[\"u\"][it], levels, cmap=\"seismic\")\n    plt.gca().set_aspect(1)\n    plt.colorbar(shrink=0.5, ticks=[-1.5, 0, 1.5], label=\"$\\\\overline{u}/u_\\infty$\")\n    plt.xlabel(\"x/c\")\n    plt.ylabel(\"y/c\")\n    plot_airfoil(AoA)\n\n    plt.subplot(212)\n    plt.contourf(mat[\"x\"], mat[\"y\"], mat[\"v\"][it], levels, cmap=\"seismic\")\n    plt.gca().set_aspect(1)\n    plt.colorbar(shrink=0.5, ticks=[-1.5, 0, 1.5], label=\"$\\\\overline{v}/u_\\infty$\")\n    plt.xlabel(\"x/c\")\n    plt.ylabel(\"y/c\")\n    plot_airfoil(AoA)\n    \n    plt.pause(0.001)",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "d12bb5aa"
    },
    {
      "cell_type": "markdown",
      "source": "Good, now we need to compute time averaged quantities. We'll use the function `np.mean`, noting that we pass the extra argument `axis=0` to tell numpy to average over the first dimension of the array, i.e. along the data axis. ",
      "metadata": {},
      "id": "d5d2881a"
    },
    {
      "cell_type": "code",
      "source": "# compute mean flow\nu_bar = np.mean(mat[\"u\"], axis=0)\nv_bar = np.mean(mat[\"v\"], axis=0)",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "acc16657"
    },
    {
      "cell_type": "markdown",
      "source": "Let's check the shape of `u_bar`:",
      "metadata": {},
      "id": "296a695a"
    },
    {
      "cell_type": "code",
      "source": "u_bar.shape",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "d50ca73f"
    },
    {
      "cell_type": "markdown",
      "source": "The output is a 2D array with size `nx, ny`, i.e. as any other snapshot. This is because the function `np.mean` has averaged over the first dimension of the 3D array  `mat[\"u\"]`, squeezing the temporal dimension away. This approach is very powerful when you have data organised in arrays, like in the present case.\n\nWe should also compute turbulence quantities, e.g the Reynolds stresses. The NumPy function `np.var` does exactly what we need, i.e. it computes the averaged squared deviation from the mean. This is exactly the energy of the fluctuations that we will try to capture using POD structures. Hence, developing a feeling for where fluctuations are more energetic will helps us later on with the interpretation of the POD modes.",
      "metadata": {},
      "id": "6e567539"
    },
    {
      "cell_type": "code",
      "source": "# compute turbulent quantiies\nu_var = np.var(mat[\"u\"], axis=0)\nv_var = np.var(mat[\"v\"], axis=0)",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "480489ff"
    },
    {
      "cell_type": "markdown",
      "source": "Let's now plot these four variables.",
      "metadata": {},
      "id": "a6f56d3f"
    },
    {
      "cell_type": "code",
      "source": "plt.figure(2, figsize=(7, 8))\nplt.subplots_adjust(top=0.96, hspace=0.1, bottom=0.05, right=0.99)\nplt.clf()\n\nplt.subplot(411)\nlevels = np.linspace(-1.5, 1.5, 50)\nplt.contourf(mat[\"x\"], mat[\"y\"], u_bar, levels, cmap=\"seismic\")\nplt.gca().set_aspect(1)\nplt.colorbar(shrink=0.65, ticks=[-1.5, 0, 1.5], label=\"$\\\\overline{u}/u_\\infty$\")\nplt.xlabel(\"x/c\")\nplt.ylabel(\"y/c\")\nplot_airfoil(AoA)\n\nplt.subplot(412)\nlevels = np.linspace(-0.5, 0.5, 50)\nplt.contourf(mat[\"x\"], mat[\"y\"], v_bar, levels, cmap=\"seismic\")\nplt.gca().set_aspect(1)\nplt.colorbar(shrink=0.65, ticks=[-0.5, 0, 0.5], label=\"$\\\\overline{v}/u_\\infty$\")\nplt.xlabel(\"x/c\")\nplt.ylabel(\"y/c\")\nplot_airfoil(AoA)\n\nplt.subplot(413)\nplt.contourf(mat[\"x\"], mat[\"y\"], u_var, 20, cmap=\"magma_r\")\nplt.gca().set_aspect(1)\nplt.gca().set_aspect(1)\nplt.colorbar(shrink=0.65, ticks=[0, 0.05, 0.1], label=\"$\\\\overline{u^\\prime u^\\prime}/u_\\infty^2$\")\nplt.xlabel(\"x/c\")\nplt.ylabel(\"y/c\")\nplot_airfoil(AoA)\n\nplt.subplot(414)\nplt.contourf(mat[\"x\"], mat[\"y\"], v_var, 20, cmap=\"magma_r\")\nplt.gca().set_aspect(1)\nplt.gca().set_aspect(1)\nplt.colorbar(shrink=0.65, ticks=[0, 0.05, 0.1], label=\"$\\\\overline{v^\\prime v^\\prime}/u_\\infty^2$\")\nplt.xlabel(\"x/c\")\nplt.ylabel(\"y/c\")\nplot_airfoil(AoA)",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "9e201243"
    },
    {
      "cell_type": "markdown",
      "source": "Can you make sense of these fields? Can you spot the wake? Does the field of the transverse velocity component make sense to you? What about the turbulence statistics? Go back and watch the animation to develop a better understanding of this flow.",
      "metadata": {},
      "id": "99ded90d"
    },
    {
      "cell_type": "markdown",
      "source": "### Task 2 - Data preparation",
      "metadata": {},
      "id": "14c76384"
    },
    {
      "cell_type": "markdown",
      "source": "To perform POD with the SVD we need to massage the data in a format suitable for the SVD function. Each snapshot needs to be reshaped as a column vector and all snapshots have to be stacked horizontally one next to the other. In addition, the $v$ velocity component data will have to be stacked below the $u$ component data. We have $m$ snapshots of size $nx \\times ny$, so the data matrix `X` will need to have size $ (2 n_x  n_y) \\times m$.\n\nTo do this, you can use a combination of the functions `np.reshape`, `np.hstack` and `np.vstack`. Check their documentation online and sketch on a piece of paper how you think the data will be structured.",
      "metadata": {},
      "id": "6fe908ac"
    },
    {
      "cell_type": "code",
      "source": "# TASK: transform all snapshots into column vectors (reshape), pack them one next to the \n#       other (hstack) and pack the two velocity components one on top of the other (vstack)\n#\nX = # write your own code here!",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "89939e2f"
    },
    {
      "cell_type": "markdown",
      "source": "If your code is correct, the following assert statements must pass without raising errors.",
      "metadata": {},
      "id": "d3144f9b"
    },
    {
      "cell_type": "code",
      "source": "assert X.shape   == (16192, 3400)\nassert X[1, 1]   == 1.0093801585989954\nassert X[-1, -1] == 0.06814444533965798",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "b6fcfc56"
    },
    {
      "cell_type": "markdown",
      "source": "The data matrix is quite large and has size `(16192, 3400)`. Let's try to plot it as if it was an image (remember what we said about the SVD in the previous weeks). ",
      "metadata": {},
      "id": "96ffa985"
    },
    {
      "cell_type": "code",
      "source": "plt.figure(3)\nplt.clf()\n\nplt.imshow(X, interpolation=\"none\", cmap=\"seismic\");\nplt.xlabel(\"time\")\nplt.ylabel(\"space\")",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "72ae8dc2"
    },
    {
      "cell_type": "markdown",
      "source": "Note that we have spatial information along the rows (for the $u$ and $v$ components) and temporal information along the columns. Zoom in to see the structure in the data. There is quite a bit of regular behaviour, and many columns look similar. Good! this means that the same data can be represented by a low-rank expansion, the POD! \n\nLet's now transform the mean flow into a column vector. Write code similar to what you have done a few cells above to reshape the mean flow components `u_bar` and `v_bar` into a column vector `x_bar`.",
      "metadata": {},
      "id": "b975b350"
    },
    {
      "cell_type": "code",
      "source": "# TASK: transform mean flow into a vector\nx_bar = # write your own code here",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "1385aee4"
    },
    {
      "cell_type": "markdown",
      "source": "Now we can compute the fluctuations. We can simply subtract `x_bar` from `X`, even if their shapes do not match because of a feature of NumPy called [broadcasting](https://numpy.org/doc/stable/user/basics.broadcasting.html).\n\nWe obtain",
      "metadata": {},
      "id": "e13eb089"
    },
    {
      "cell_type": "code",
      "source": "# compute fluctuation\nXp = X - x_bar",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "a61f4ce6"
    },
    {
      "cell_type": "markdown",
      "source": "where `p` stands for \"prime\". Check the shape of `Xp` - does it make sense to you?",
      "metadata": {},
      "id": "f5a76f95"
    },
    {
      "cell_type": "markdown",
      "source": "### Task 3 - Performing POD",
      "metadata": {},
      "id": "2920b98e"
    },
    {
      "cell_type": "markdown",
      "source": "To perform POD we need to first think about what the correct inner product is based on the data we have. PIV data is almost always available on a uniform mesh of square or rectangular cells, and each velocity vector represents the average velocity over the cell. Let's check the grid using the function `np.diff`. This can be used to compute the grid spacing, in both the `x` and `y` directions.",
      "metadata": {},
      "id": "6234aedd"
    },
    {
      "cell_type": "code",
      "source": "np.diff(mat[\"x\"], axis=0)",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "d270a219"
    },
    {
      "cell_type": "code",
      "source": "np.diff(mat[\"y\"], axis=1)",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "10bb049d"
    },
    {
      "cell_type": "markdown",
      "source": "We see that the grid is indeed uniform with square cells with area $A_c = 0.02032577^2$. ",
      "metadata": {},
      "id": "bc07e2cd"
    },
    {
      "cell_type": "code",
      "source": "A_c = 0.02032577**2",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "3e1f5218"
    },
    {
      "cell_type": "markdown",
      "source": "In this case we probably do not need to worry much about modying the SVD algorithm as all cells contribute equally to the evaluation of integrals. The practical consequence of this is that the POD modes and modal energies would be off by a constant factor. This is not so important in this case, because a) for the POD modes we care about their spatial structure, and not their amplitude and b) for the modal energies we care about their relative importance, e.g. when we plot the relative information content.\n\nIn any case, we'll use the correct algorithm, just to make some practice.",
      "metadata": {},
      "id": "51012cd8"
    },
    {
      "cell_type": "markdown",
      "source": "We will use the `sparse` package from `scipy`, as it contains some classes for storing a large diagonal matrix very efficiently, i.e. not using a dense matrix, but only storing the nonzero elements. You can read more about the topic [https://en.wikipedia.org/wiki/Sparse_matrix](here).\n\nLet's import the package",
      "metadata": {},
      "id": "715e7c69"
    },
    {
      "cell_type": "code",
      "source": "import scipy.sparse as ssp",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "4162ca01"
    },
    {
      "cell_type": "markdown",
      "source": "and let's create the mass matrix, using the same cell area for all points.",
      "metadata": {},
      "id": "235c7b1c"
    },
    {
      "cell_type": "code",
      "source": "W = ssp.diags(np.repeat(A_c, 2*nx*ny))",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "bdeae515"
    },
    {
      "cell_type": "markdown",
      "source": "Note how the size of this matrix is twice the number of grid points, becase a snapshot vector contains both the $u$ and $v$ components. \n\nHow would we use this? Well, let's compute the norm of one of the snapshots",
      "metadata": {},
      "id": "bfee88d3"
    },
    {
      "cell_type": "code",
      "source": "X[:, 0].T @ W @ X[:, 0]",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "3329fcd9"
    },
    {
      "cell_type": "markdown",
      "source": "For the full algorithm, we need to form the Choleski factor, and its inverse for solving for the POD modes. Again, we use `diags` and just compute the decomposition manually since `W` is diagonal. \n\nYou should try doing this yourself.",
      "metadata": {},
      "id": "725d7f29"
    },
    {
      "cell_type": "code",
      "source": "# TASK: compute factor of the Cholesky decomposition\nL = # write your own code\n\n# and its inverse\nLinv = # write your own code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "6d3ac92e"
    },
    {
      "cell_type": "markdown",
      "source": "In the next cell, you should take the SVD and compute singular vectors/values. Remember that you very likely want the economy SVD.",
      "metadata": {},
      "id": "22f99331"
    },
    {
      "cell_type": "code",
      "source": "# TASK: compute the svd of an appropriate matrix\nU, S, VT = # write your own code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "e18d9bc5"
    },
    {
      "cell_type": "markdown",
      "source": "Running the SVD for such a large matrix takes a bit. Let's examine the shape of the outputs. Let's start with the right singular vectors `U`",
      "metadata": {},
      "id": "c69d5361"
    },
    {
      "cell_type": "code",
      "source": "U.shape",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "0fed06fc"
    },
    {
      "cell_type": "markdown",
      "source": "The data is organised exactly as the data matrix `Xp`, i.e. we have space (and velocity components along the rows) and modal index along the columns.",
      "metadata": {},
      "id": "8e011412"
    },
    {
      "cell_type": "code",
      "source": "S",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "4e5808a8"
    },
    {
      "cell_type": "markdown",
      "source": "`S` is a 1D array. It will be convenient to transform this into a matrix later on. \n\nThe array `VT` contains the right singular vectors in each of its rows. The function `np.linalg.svd` returns it transposed by default, so make sure you understand how the data in this array is structured.\n\n\nLet's now construct the POD modes, temporal coefficients and modal energies. For the POD modes, note that",
      "metadata": {},
      "id": "2de5ec0d"
    },
    {
      "cell_type": "code",
      "source": "PHI = Linv.T @ U",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "5e8181fc"
    },
    {
      "cell_type": "markdown",
      "source": "These modes should be orthogonal and have unit norm. Let's try subtracting the identity matrix from the product of the modes with themselves",
      "metadata": {},
      "id": "40cf9d24"
    },
    {
      "cell_type": "code",
      "source": "np.linalg.norm(PHI.T @ W @ PHI - ssp.diags(np.ones(m)))",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "0183ef92"
    },
    {
      "cell_type": "markdown",
      "source": "OK!",
      "metadata": {},
      "id": "61eb5bc1"
    },
    {
      "cell_type": "markdown",
      "source": "Finally, we \"unpack\" the $u$ and $v$ components of the POD, simply by splitting in half the rows of `PHI`:",
      "metadata": {},
      "id": "17442798"
    },
    {
      "cell_type": "code",
      "source": "PHI_u = PHI[:nx*ny, :]\nPHI_v = PHI[nx*ny:, :]",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "7aad92c4"
    },
    {
      "cell_type": "markdown",
      "source": "Note how the top half is the $u$ component of the POD mode and the bottom half is the $v$ component, exactly how we packed the data few cells above here.",
      "metadata": {},
      "id": "49eb9f6f"
    },
    {
      "cell_type": "markdown",
      "source": "Let's now obtain the temporal coefficients. I will obtain them from projecting the snapshots onto the POD modes. For the projection, I am using the mass matrix, so that I computing the correct inner product:",
      "metadata": {},
      "id": "168c6030"
    },
    {
      "cell_type": "code",
      "source": "A = Xp.T @ W @ PHI",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "5502898d"
    },
    {
      "cell_type": "markdown",
      "source": "Let's compute the modal energies",
      "metadata": {},
      "id": "6aca78e7"
    },
    {
      "cell_type": "code",
      "source": "# extract modal energies on the diagonal\nlambdas = S**2 / m",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "d6fc75f5"
    },
    {
      "cell_type": "markdown",
      "source": "In the following cells, you should define a function to compute the relative information content from the modal energies and then plot the modal energies and the RIC metric. Use log scales when appropriate. You might wish to use the functions `np.cumsum` and `sum`.",
      "metadata": {},
      "id": "f2ac0e04"
    },
    {
      "cell_type": "code",
      "source": "def ric(lambdas):\n    \"\"\" Compute relative information content from the modal energies \"\"\"\n    return np.cumsum(lambdas)/sum(lambdas)",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "841e0663"
    },
    {
      "cell_type": "code",
      "source": "fig = plt.figure(4)\nplt.subplots_adjust(wspace=0.35)\nplt.clf()\n\n# array for plotting starting from 1\ni_or_k = np.arange(len(lambdas)) + 1\n\nplt.subplot(121)\nplt.plot(i_or_k, lambdas, \".\")\nplt.ylim(1e-8, 1e-2)\nplt.grid(1)\nplt.xlabel(\"i\")\nplt.ylabel(\"$\\lambda_i$\")\nplt.yscale(\"log\")\n\nplt.subplot(122)\nplt.plot(i_or_k, ric(lambdas), \".\")\nplt.xlabel(\"k\")\nplt.ylabel(\"RIC(k)\")\nplt.grid(1)",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "a2d98715"
    },
    {
      "cell_type": "markdown",
      "source": "The modal energies drop quite fast, but it takes 130 modes to capture 90% of the energy in the data. In you spare time, you should compare the modal energies of the two datasets, for angle or attack of 0 and 10 degrees. This will give you some insight into the complexity of the two flows.",
      "metadata": {},
      "id": "cc5d76d1"
    },
    {
      "cell_type": "markdown",
      "source": "### Task 4: analysing the results",
      "metadata": {},
      "id": "b677d780"
    },
    {
      "cell_type": "markdown",
      "source": "We'll start by plotting contours of the first POD mode ($v$ velocity component) and also add vectors, to get an idea of the flow direction. The crucial thing is that we  need to reshape the 1d array for the POD mode into a 2D array that can be fed to `plt.contourf`. We can simply use the NumPy function `np.reshape` for this",
      "metadata": {},
      "id": "0b7c5724"
    },
    {
      "cell_type": "code",
      "source": "phi_u = np.reshape(PHI_u[:, 0], (nx, ny))\nphi_v = np.reshape(PHI_v[:, 0], (nx, ny))",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "f43b9b85"
    },
    {
      "cell_type": "code",
      "source": "plt.figure(5)\nplt.clf()\n\nlevels = np.linspace(-5, 5, 100)\n\nplt.contourf(mat[\"x\"], mat[\"y\"], phi_v, levels, cmap=\"seismic\")\n\n# scale controls the length of the vector (lower scale -> longer vectors)\nskip = 3\nplt.quiver(mat[\"x\"][::skip, ::skip], \n           mat[\"y\"][::skip, ::skip],\n           phi_u[::skip, ::skip],\n           phi_v[::skip, ::skip], scale=30)\n\n\nplt.xlabel(\"x/c\")\nplt.ylabel(\"y/c\")\nplt.gca().set_aspect(1)\nplt.grid(1)\n\nplot_airfoil(AoA)",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "39c2cd7f"
    },
    {
      "cell_type": "markdown",
      "source": "As you can see, the first POD mode looks like a wave in the streamwise direction and  captures the process of shedding vortical structures from the airfoil. Change the code above to plot the $u$ component and check if the sign of the velocities matches with the expect flow direction. Plot also mode 2. As you can see this looks very similiar to mode 1 (note Python starts at zero), but it is shifted downstream by half a wave period. This is common for periodic flow with strongly convective components, as you need two structures (a sine and a cosine) to represent any arbitrary phase.\n\nTry also plotting other modes, e.g. modes 4 or 20. As you can see, the higher the mode index, the more complex the flow behaviour usually becomes.",
      "metadata": {},
      "id": "9f5f43a3"
    },
    {
      "cell_type": "markdown",
      "source": "We can also plot the temporal coefficients. Let's also construct an array of times.",
      "metadata": {},
      "id": "4cc2b26e"
    },
    {
      "cell_type": "code",
      "source": "plt.figure(6)\nplt.clf()\nplt.subplots_adjust(wspace=0.4, hspace=0.4)\n\ntt = np.arange(m) * mat[\"dt\"][0][0]\n\n# mode 1 and 2\nplt.subplot(2, 1, 1)\nplt.plot(tt, A[:, 0], label=\"$a_1(t)$\")\nplt.plot(tt, A[:, 1], label=\"$a_2(t)$\")\nplt.legend()\nplt.grid(1)\nplt.ylabel(\"$a_i(t)$\")\nplt.xlabel(\"$t u_\\infty / c$\")\n\n# mode 3 and 4\nplt.subplot(2, 1, 2)\nplt.plot(tt, A[:, 2], label=\"$a_3(t)$\")\nplt.plot(tt, A[:, 3], label=\"$a_4(t)$\")\nplt.grid(1)\nplt.legend()\nplt.ylabel(\"$a_i(t)$\")\nplt.xlabel(\"$t u_\\infty / c$\")",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "ba75f139"
    },
    {
      "cell_type": "markdown",
      "source": "As you can see, the coefficients are highly oscillatory, but they are far from being regular sine/cosine waves. The signals look modulated as if there are multiple frequency components mixed together. This is actually a property of POD, i.e. that it can mix together spatial behaviour that occurs at different frequencies. On the other hand, DMD can separate spatial structures that evolve at different frequencies, which is useful to distinguish independent flow processes.",
      "metadata": {},
      "id": "0220afba"
    },
    {
      "cell_type": "markdown",
      "source": "### Task 5: low rank reconstruction",
      "metadata": {},
      "id": "e3be45fb"
    },
    {
      "cell_type": "markdown",
      "source": "In the last task of this lab, we are going to perform a low-rank reconstruction of the velocity fluctuation, using POD modes. Think about the cat example we have done a few lectures ago, where we have reconstructed the whole image (the whole dataset) with an increasing number of left/right singular vectors.",
      "metadata": {},
      "id": "50cf1075"
    },
    {
      "cell_type": "markdown",
      "source": "Let's attempt a rank-two reconstruction using two POD modes. To achieve this we take the first two columns of `PHI` and multiply by the first two columns of `A`, then transpose. ",
      "metadata": {},
      "id": "1bef34b7"
    },
    {
      "cell_type": "code",
      "source": "# rank-k reconstruction\nk = 2\nXp_r = PHI[:, :k] @ A[:, :k].T",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "99cb1854"
    },
    {
      "cell_type": "markdown",
      "source": "The product of these matrices gives us a matrix with the same shape of the data matrix. We'll append `_r`, for \"reconstructed\" to distinguish is from the original fluctuation data `Xp`.",
      "metadata": {},
      "id": "ed2eb123"
    },
    {
      "cell_type": "code",
      "source": "Xp_r.shape",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "c02edc3b"
    },
    {
      "cell_type": "markdown",
      "source": "What should be the rank of this matrix? Let's check:",
      "metadata": {},
      "id": "e24a6c34"
    },
    {
      "cell_type": "code",
      "source": "np.linalg.matrix_rank(Xp_r)",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "26c5b638"
    },
    {
      "cell_type": "markdown",
      "source": "Yes, two. This is consistent with the fact that we have constructed this matrix from the product of other smaller matrices.\n\nThe matrix `Xp_r` contains the reconstructed velocity fluctuation for all available snapshots. We can make an animation of this data and compare it with the original data. Note how I am unpacking the u and v components of the reconstructed snapshot vectors and then reshaping these into 2D arrays with size compatible with our grid data.\n\nWe plot the reconstructed flow in the top panel and the original data in the bottom one. We'll be plotting the transverse velocity component $v$ which is more indicative of large scale structures then the $u$ component",
      "metadata": {},
      "id": "2506edf7"
    },
    {
      "cell_type": "code",
      "source": "plt.figure(8)\nplt.subplots_adjust(right=0.99)\n\nlevels = np.linspace(-1, 1, 20)\nskip = 2\nscale = 20\n\nfor it in range(0, 100, 5):\n    plt.clf()\n    \n    # plot reconstructed snapshot\n    plt.subplot(211)\n    up_r = np.reshape(Xp_r[:nx*ny, it], (nx, ny))\n    vp_r = np.reshape(Xp_r[nx*ny:, it], (nx, ny))\n\n    plt.contourf(mat[\"x\"], mat[\"y\"], vp_r, levels, cmap=\"seismic\")\n    plt.colorbar(shrink=0.6, label=\"$v^\\prime_r(x, y, t)$\", ticks=[-1, 0, 1])\n    plt.gca().set_aspect(1)\n    plt.title(\"Reconstructed\")\n    \n    # the scale argument controls the length of the vector\n    # (lower scale -> longer vectors)\n    plt.quiver(mat[\"x\"][::skip, ::skip], \n               mat[\"y\"][::skip, ::skip],\n               up_r[::skip, ::skip],\n               vp_r[::skip, ::skip], scale=scale)\n\n    plot_airfoil(AoA)\n    plt.xlabel(\"x/c\")\n    plt.ylabel(\"y/c\")\n    plt.grid(1)\n    \n    # plot actual snapshot\n    plt.subplot(212)\n    up = np.reshape(Xp[:nx*ny, it], (nx, ny))\n    vp = np.reshape(Xp[nx*ny:, it], (nx, ny))\n\n    plt.contourf(mat[\"x\"], mat[\"y\"], vp, levels, cmap=\"seismic\")\n    plt.colorbar(shrink=0.6, label=\"$v^\\prime(x, y, t)$\", ticks=[-1, 0, 1])\n    plt.gca().set_aspect(1)\n    plt.title(\"Original\")\n    \n    # the scale argument controls the length of the vector\n    # (lower scale -> longer vectors)\n    plt.quiver(mat[\"x\"][::skip, ::skip], \n               mat[\"y\"][::skip, ::skip],\n               up[::skip, ::skip],\n               vp[::skip, ::skip], scale=scale)\n\n    plot_airfoil(AoA)\n    plt.xlabel(\"x/c\")\n    plt.ylabel(\"y/c\")\n    plt.grid(1)\n    \n    plt.pause(0.001)",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "90f1caf4"
    },
    {
      "cell_type": "markdown",
      "source": "There are several remarks to be made:\n\n- the low rank reconstructed velocity field is much less noisy. All the noise upstream the airfoil due to measurement error has been removed. In fact, POD (and the SVD) works well as a denoisin technique.\n\n- the velocity fluctuations in the wake are more intense than what the reconstructed field predicts. This is normal, as with two modes we have only captured a fraction of the total energy of the fluctuations. \n\n- we have not really captured any of flow activity that features prominently in the near wake, e.g. the flow separation process starting at the airfoil's leading edge.",
      "metadata": {},
      "id": "fdded55b"
    },
    {
      "cell_type": "markdown",
      "source": "### Task 7 - other things to work on in your own time",
      "metadata": {},
      "id": "28d38eea"
    },
    {
      "cell_type": "markdown",
      "source": "Now, here's a couple of interesting experiments to try at home.\n\n- try reconstructing the velocity fluctuations using only the first POD mode. You'll see that the ability of the low-rank reconstruction to model the convection of flow structures in the wake is lost. You need two modes shifted by half a period to describe this behaviour.\n\n- try a higher-rank reconstruction, e.g. with 10 or 20 modes.\n\n- explore the other dataset, for angle of attack $\\alpha=0$. Look at the POD modes and the temporal coefficients, and compare the drop of the modal energies we the dataset we have used in this lab.",
      "metadata": {},
      "id": "bca20736"
    }
  ]
}